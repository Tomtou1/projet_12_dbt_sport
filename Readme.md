# ğŸƒâ€â™‚ï¸ Plateforme d'Analyse des ActivitÃ©s Sportives

## ğŸ“‹ Description

Plateforme moderne de **data engineering** pour suivre, analyser et rÃ©compenser les activitÃ©s sportives des salariÃ©s. Pipeline ELT complet avec accent sur la **qualitÃ© des donnÃ©es**, la **confidentialitÃ© RGPD** et la **scalabilitÃ©**.

### ğŸ“Š Diagramme des Flux

```mermaid
graph TB
    subgraph Sources["ğŸ“ Sources de DonnÃ©es"]
        RH[Excel RH]
        Sport[Excel Sport]
        API[API Google Maps]
    end
    
    subgraph Airflow["ğŸ”„ Apache Airflow - Orchestration"]
        Sched[Scheduler<br/>Toutes les 20min]
        DAG[DAG sport_pipeline]
    end
    
    subgraph Pipeline["âš™ï¸ Pipeline ETL"]
        Extract[Producer Strava<br/>Docker Task]
        Transform[dbt Transform<br/>Docker Task]
        Notify[Slack Sender<br/>Docker Task]
    end
    
    subgraph Storage["ğŸ’¾ Stockage"]
        PG[(PostgreSQL 16)]
        Bronze[Couche Bronze<br/>DonnÃ©es brutes]
        Silver[Couche Silver<br/>DonnÃ©es nettoyÃ©es]
        Gold[Couche Gold<br/>AgrÃ©gats business]
    end
    
    subgraph Monitoring["ğŸ“ˆ Monitoring"]
        Prom[Prometheus<br/>MÃ©triques]
        Graf[Grafana<br/>Dashboards]
        Stats[StatsD<br/>Airflow metrics]
    end
    
    subgraph Viz["ğŸ“Š Visualisation"]
        Superset[Apache Superset<br/>:8088]
    end
    
    subgraph Notif["ğŸ’¬ Notifications"]
        Slack[Slack Webhook]
    end
    
    RH --> Extract
    Sport --> Extract
    API --> Extract
    
    Sched --> DAG
    DAG --> Extract
    Extract --> PG
    PG --> Bronze
    
    DAG --> Transform
    Bronze --> Transform
    Transform --> Silver
    Silver --> Gold
    
    DAG --> Notify
    Gold --> Notify
    Notify --> Slack
    
    Gold --> Superset
    
    Airflow -.mÃ©triques.-> Stats
    Stats --> Prom
    Prom --> Graf
    PG -.mÃ©triques.-> Prom
    
    style Airflow fill:#e1f5ff
    style Pipeline fill:#fff4e1
    style Storage fill:#e8f5e9
    style Monitoring fill:#f3e5f5
    style Viz fill:#ffe0e0
```

### ğŸ¯ FonctionnalitÃ©s Principales

- **ğŸ“Š Suivi des ActivitÃ©s** : Running, natation, cyclisme, randonnÃ©e, tennis
- **ğŸ¢ DonnÃ©es RH** : Business units, salaires, trajets domicile-travail
- **ğŸ’° Calcul des Primes** : MobilitÃ© et activitÃ©s sportives
- **ğŸ”„ Orchestration Airflow** : Pipeline automatisÃ© toutes les 20 minutes
- **ğŸ“ˆ Monitoring** : Prometheus, Grafana, StatsD
- **ğŸ’¬ Notifications Slack** : Alertes quotidiennes automatiques
- **ï¿½ ConformitÃ© RGPD** : Pseudonymisation, minimisation des donnÃ©es

### ğŸ› ï¸ Stack Technologique

- **Orchestration** : Apache Airflow 3.1.7 (CeleryExecutor + Redis)
- **Base de donnÃ©es** : PostgreSQL 16 (WAL activÃ©)
- **Transformation** : dbt (architecture mÃ©daillon Bronze/Silver/Gold)
- **Monitoring** : Prometheus + Grafana + StatsD
- **Visualisation** : Apache Superset
- **Containerisation** : Docker Compose
- **Notifications** : Slack Webhooks


---

## ğŸ”„ Orchestration avec Apache Airflow

### Architecture Airflow

- **ExÃ©cuteur** : CeleryExecutor pour parallÃ©lisation
- **Broker** : Redis pour gestion des tÃ¢ches
- **Scheduler** : ExÃ©cution toutes les 20 minutes (`*/20 * * * *`)
- **Workers** : ExÃ©cution de tÃ¢ches Docker via DockerOperator

### DAG `sport_pipeline`

```python
# Flux : load_data â†’ run_dbt â†’ notify_slack
1. load_strava_data    # Extraction donnÃ©es (image: producer_history_strava)
2. run_dbt             # Transformations dbt (image: elt_dbt)
3. notify_slack        # Notifications (image: slack_sender)
```

### Services Airflow

| Service | Port | Description |
|---------|------|-------------|
| `airflow-webserver` | 8080 | Interface web (admin/admin) |
| `airflow-scheduler` | - | Planificateur DAGs |
| `airflow-worker` | - | ExÃ©cuteur de tÃ¢ches |
| `airflow-triggerer` | - | DÃ©clenchement asynchrone |
| `redis` | 6379 | Message broker |
| `postgres` | 5432 | Metastore Airflow |

### AccÃ¨s & Monitoring Airflow

```bash
# Interface web
http://localhost:8080
Login: airflow / airflow

# Logs
docker compose logs -f airflow-scheduler
docker compose logs -f airflow-worker

# CLI
docker exec -it airflow-worker airflow dags list
docker exec -it airflow-worker airflow tasks test sport_pipeline load_strava_data 2026-02-23
```

---

## ğŸ“ˆ Monitoring & ObservabilitÃ©

### Stack de Monitoring

| Composant | Port | Fonction |
|-----------|------|----------|
| **Prometheus** | 9090 | Collecte et stockage mÃ©triques |
| **Grafana** | 3000 | Dashboards de visualisation |
| **StatsD** | 9125/8125 | Export mÃ©triques Airflow |

### MÃ©triques CollectÃ©es

#### Airflow (via StatsD)
- DurÃ©e d'exÃ©cution des DAGs
- Taux de succÃ¨s/Ã©chec des tasks
- Latence du scheduler
- Utilisation des workers

#### PostgreSQL
- Connexions actives
- RequÃªtes lentes
- Taille de la base
- Performance des index

#### SystÃ¨me
- CPU, RAM, Disk I/O
- Ã‰tat des conteneurs Docker
- RÃ©seau inter-services

### Configuration Prometheus

```yaml
# prometheus.yml (exemple)
scrape_configs:
  - job_name: 'airflow'
    static_configs:
      - targets: ['statsd-exporter:9102']
  
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres_sport:5432']
```

### Dashboards Grafana

AccÃ©der Ã  Grafana : `http://localhost:3000`

**Dashboards disponibles :**
- Airflow DAG Performance
- PostgreSQL Metrics
- Docker Container Health
- Pipeline Execution Timeline

### Alerting

Prometheus supporte l'alerting via AlertManager :
- DAG Ã©chec > 3 fois
- Utilisation DB > 80%
- Latence pipeline > 10min

---

## ğŸš€ Performance & ScalabilitÃ©

### Optimisations

1. **Traitement IncrÃ©mental dbt**
   - ModÃ¨les incrÃ©mentaux : seules les nouvelles donnÃ©es
   - `unique_key='id_activity'` pour upserts efficaces
   - Temps de traitement rÃ©duit de 90%

2. **Vues MatÃ©rialisÃ©es**
   - Silver : Tables matÃ©rialisÃ©es (donnÃ©es nettoyÃ©es)
   - Gold : AgrÃ©gats prÃªts pour BI
   - RequÃªtes Superset < 100ms

3. **Airflow CeleryExecutor**
   - ParallÃ©lisation des tÃ¢ches
   - ScalabilitÃ© horizontale des workers
   - Retry automatique sur Ã©chec

4. **PostgreSQL WAL**
   - Write-Ahead Logging pour durabilitÃ©
   - `wal_level=logical` pour CDC futur
   - Connexion pooling activÃ©

### CapacitÃ©s

- **Actuel** : 125+ activitÃ©s, 50+ salariÃ©s
- **ProjetÃ©** : Millions d'enregistrements via partitionnement PostgreSQL
- **ScalabilitÃ©** : Architecture multi-workers Airflow

---

## ğŸ”’ SÃ©curitÃ© & RGPD

### Protection des DonnÃ©es

1. **Variables d'Environnement** : Tous les secrets dans `.env` (exclu de Git)
2. **RÃ©seau IsolÃ©** : Bridge Docker `sport_network`
3. **Pseudonymisation** : Algorithme de divulgation progressive pour noms
4. **Anonymisation Adresses** : Seule la distance conservÃ©e, pas la localisation
5. **Minimisation** : Salaires agrÃ©gÃ©s, non exposÃ©s en dashboards

### ConformitÃ© RGPD

âœ… Consentement volontaire  
âœ… Transparence de l'utilisation  
âœ… Droits d'accÃ¨s et export  
âœ… Privacy by Design  
âœ… TraÃ§abilitÃ© via dbt lineage  

### Recommandations

- [ ] Politique de rÃ©tention (7 ans max)
- [ ] Audit logging PostgreSQL
- [ ] SSL/TLS pour donnÃ©es en transit
- [ ] Droit Ã  l'oubli automatisÃ©

---

## ğŸ—ï¸ Architecture des DonnÃ©es

### MÃ©daillon Bronze â†’ Silver â†’ Gold

```
Bronze (Raw)              Silver (Clean)           Gold (Aggregate)
â”œâ”€ sport_activities   â†’   silver_activities    â†’  gold_per_bu
â”œâ”€ sport_enterprise   â†’   silver_enterprise    â†’  gold_prime_2025
â””â”€ rh_info            â†’   silver_rh_info       â†’  gold_slack_messages
                                                   gold_moyen_deplac
                                                   gold_incorrect_transport
```

### Tables Gold - Business Logic

| Table | Description | Refresh |
|-------|-------------|---------|
| `gold_sport_activities_per_bu` | ActivitÃ©s par BU (12 mois) | IncrÃ©mental |
| `gold_sport_activities_prime_last_year` | Ã‰ligibles prime (>3 activitÃ©s 2025) | IncrÃ©mental |
| `gold_slack_message_activities` | ActivitÃ©s du jour | IncrÃ©mental |
| `gold_potential_moyen_deplac_bonus` | Ã‰ligibles prime mobilitÃ© | Table |
| `gold_incorrect_moyen_deplacement` | Transports invalides | Table |

**RÃ¨gles de Primes :**
- **Prime Sportive** : >3 activitÃ©s en 2025
- **Prime MobilitÃ©** : Distance < 25km, transport â‰  marche/vÃ©lo, 5% salaire brut

---

## ğŸ› ï¸ Installation & Configuration

### PrÃ©requis

- Docker & Docker Compose
- Fichier `.env` :

```bash
# PostgreSQL
POSTGRES_USER=postgresuser
POSTGRES_PASSWORD=postgrespw
POSTGRES_DB=sport_activities_db

# Superset
SUPERSET_SECRET_KEY=your_secret_key

# Slack
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Google Maps (optionnel)
GCP_key=your_google_api_key

# Airflow
AIRFLOW_UID=50000
_AIRFLOW_WWW_USER_USERNAME=airflow
_AIRFLOW_WWW_USER_PASSWORD=airflow
```

### DÃ©marrage Rapide

```bash
# Initialiser Airflow (premiÃ¨re fois)
docker compose up airflow-init

# Lancer la stack complÃ¨te
docker compose up -d

# VÃ©rifier les services
docker compose ps

# AccÃ¨s aux interfaces
open http://localhost:8080  # Airflow
open http://localhost:8088  # Superset
open http://localhost:3000  # Grafana
open http://localhost:9090  # Prometheus
```

### Commandes Utiles

```bash
# Airflow
docker exec -it airflow-worker airflow dags trigger sport_pipeline
docker compose logs -f airflow-scheduler

# dbt
docker exec -it elt_dbt dbt run
docker exec -it elt_dbt dbt test
docker exec -it elt_dbt dbt docs generate

# Monitoring
docker compose logs -f prometheus
docker compose logs -f grafana

# PostgreSQL
docker exec -it postgres_sport psql -U postgresuser -d sport_activities_db
```

---

## ğŸ“Š Visualisation & Dashboards

### Apache Superset

**AccÃ¨s** : `http://localhost:8088` (admin/admin)

**Dashboards disponibles :**
- ActivitÃ©s par Business Unit
- Top salariÃ©s actifs
- Primes de mobilitÃ©
- Transports invalides
- Tendances mensuelles

**Import dashboards :**
```bash
# Depuis l'interface Superset : Settings > Import
# Fichier : export.zip
```

### Grafana

**AccÃ¨s** : `http://localhost:3000`

**Dashboards :**
- Airflow Pipeline Metrics
- PostgreSQL Performance
- System Resources
- Container Health

---

## ğŸ“ˆ Logs & Debugging

### Localisation des Logs

```bash
# Airflow logs
logs/dag_id=sport_pipeline/run_id=*/

# dbt logs
dbt/logs/dbt.log

# Pipeline logs (cron)
cron/logs/pipeline.log

# Docker logs
docker compose logs <service_name>
```

### Debugging

```bash
# VÃ©rifier statut DAG
docker exec -it airflow-worker airflow dags state sport_pipeline

# Test task isolÃ©e
docker exec -it airflow-worker airflow tasks test sport_pipeline load_strava_data 2026-02-23

# Logs PostgreSQL
docker compose logs postgres_sport

# MÃ©triques temps rÃ©el
watch -n 2 'docker compose ps'
```

---

## ğŸ”® Roadmap

### Court Terme (3-6 mois)
- [ ] Streaming temps rÃ©el (Kafka + Debezium CDC)
- [ ] ML dÃ©tection fraude activitÃ©s
- [ ] dbt-expectations pour tests avancÃ©s
- [ ] Portail self-service salariÃ©s

### Moyen Terme (6-12 mois)
- [ ] IntÃ©gration API Strava/Garmin/Fitbit
- [ ] OAuth2 pour appareils personnels
- [ ] Politique rÃ©tention RGPD automatisÃ©e
- [ ] CI/CD GitHub Actions
- [ ] Terraform IaC pour AWS

### Long Terme (12+ mois)
- [ ] Architecture multi-tenant
- [ ] Recommandations IA personnalisÃ©es
- [ ] API publique + Webhooks
- [ ] Certification ISO 27001
- [ ] Marketplace templates analytics

---

## ğŸ¤ Contribuer

1. Fork le repo
2. Branche feature (`git checkout -b feature/amazing`)
3. Commit (`git commit -m 'Add amazing feature'`)
4. Push (`git push origin feature/amazing`)
5. Pull Request

---

## ğŸ“„ Licence & Support

Projet dÃ©veloppÃ© dans le cadre du cursus **Data Engineering OpenClassrooms**.

**Support :** Issues GitHub ou contact thomas.leroy@example.com

---

*DerniÃ¨re mise Ã  jour : FÃ©vrier 2026 - v2.0 (Airflow + Monitoring)*
